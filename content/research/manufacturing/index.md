---
title: Intelligent Manufacturing Robotics
toc: true
reading_time: false
pager: false
show_date: false
authors: [matteosaveriano, marcoroveri, songchungao, matteodallevedove, elenabasei, veronicacampana, edoardolamon, luigipalopoli, danielefontanelli]
summary: |-
 Robotics and artificial intelligence are revolutionising the manufacturing industry by enabling greater efficiency, precision, and adaptability. We focus on making robots adaptable to a changing working landscape in which humans and intelligent machines are asked to cooperate in a cohesive manner, relieving the human worker from repetitive, unergonomic and unhealthy tasks.
---

## Overview

Robotics involves the design and deployment of automated machines that can perform complex tasks such as assembly and disassembly, polishing and quality inspection with minimal human intervention. AI enhances these systems by equipping them with the ability to analyse data, learn from patterns and human behaviours, and make decisions in real-time, enabling smarter, healthier and more flexible production processes. Together, the IDRA robotics and AI solutions contribute to advancements like **human aware motion planning**, **imitation and transfer learning**, **flexible localisation and estimation** and **activity scheduling and motion planning**, driving innovation in modern manufacturing.

### Human Aware Motion Planning

Human-aware motion planning is a critical aspect of modern manufacturing, where robots (or cobots) and humans increasingly collaborate in shared workspaces. This approach ensures that robotic systems can operate efficiently while prioritising human safety and comfort. Also, this approach not only enhances safety but also improves productivity by enabling smoother and more intuitive collaboration between humans and robots, paving the way for more adaptive and human-centric manufacturing environments.  Our research aims to:

- Human motion models leveraging sensors, machine learning, and predictive algorithms. 
- Stochastic predictions and classification of human motions.
- Safe reactive motion planning, reactive control and safe reinforcement learning.


<!-- ### Imitation and transfer learning (Matteo)

TBD

- TBD
- TBD
- TBD -->


### Flexible localisation and estimation

In modern manufacturing, localisation of Automated Guided Vehicles (AGVs) is vital for efficient navigation and material handling. Accurate position tracking ensures seamless movement and reduces operational delays. Robot state estimation complements this by providing real-time data on the robot's position, orientation, and operational state, enabling precise task execution. Ergodic control optimises robot motion by ensuring uniform exploration of a workspace, balancing efficiency and thoroughness in tasks like inspection or material distribution. Together, these technologies enhance manufacturing automation, improve workflow efficiency, and minimise errors. Key features of our research include:

- Advanced sensor fusion techniques and machine learning-based models for robust robot localisation in dynamic manufacturing environments.
- Adaptive ergodic control strategies for multi-robot systems and active sensing in large-scale manufacturing facilities.
- Autonomous decision-making systems for dynamic task allocation based on robot state estimation.


<!-- ### Activity scheduling and motion planning (Marco, Luigi)

TBD - add orienteering

- TBD
- TBD
- TBD -->


## The Team

- [Matteo Saveriano](/author/edoardo-lamon/) - Professor
- [Marco Roveri](/author/davide-nardi/) - Professor
- [Songchun Gao](/author/luca-beber/) - Researcher
- [Matteo Dalle Vedove](/author/) - PhD Student
- [Elena Basei](/author/) - PhD Student
- [Veronica Campana](/author/) - PhD Student
- [Edoardo Lamon](/author/edoardo-lamon/) - Collaborator

## Publications and Events

For detailed information on our research and publications, visit our [publications page](/publication/).

## Contact Us

For more information about our research or to collaborate with us, please contact [songchun.gao@unitn.it](mailto:songchun.gao@unitn.it).

---